{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "atmospheric-worth",
   "metadata": {},
   "source": [
    "### Initization of Input file and word list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "conventional-parks",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs and Outputs\n",
    "# Custom list of UK and US Words are zipped together \n",
    "\n",
    "import re\n",
    "import docx2txt\n",
    "import timeit\n",
    "from collections import Counter\n",
    "from docx import Document\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "my_text = docx2txt.process(r\"C:\\Users\\91824\\Downloads\\Finding-US-UK-Words\\Coal Ash Review R2-v5.docx\")\n",
    "filename = r\"C:\\Users\\91824\\Downloads\\Finding-US-UK-Words\\Coal Ash Review R2-v5.docx\"\n",
    "output_name = r\"C:\\Users\\91824\\Downloads\\Finding-US-UK-Words\\Coal Ash Review R2-v5_final.docx\"\n",
    "doc = Document(filename)\n",
    "\n",
    "\n",
    "def Initial():\n",
    "    start_time = timeit.default_timer()\n",
    "#     my_input = input(\"Please enter an input: \")\n",
    "\n",
    "    \n",
    "    with open(r\"C:\\Users\\91824\\Downloads\\Finding-US-UK-Words\\uk.txt\") as f1:\n",
    "        x= f1.read().split()\n",
    "\n",
    "    with open(r\"C:\\Users\\91824\\Downloads\\Finding-US-UK-Words\\Us.txt\") as f2:\n",
    "        y= f2.read().split()\n",
    "\n",
    "    US_UK  = dict(zip(x, y))\n",
    "    return US_UK,x,y,start_time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "strategic-endorsement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are three possibities for a word to get matched with either British or American words\n",
    "# Total Matched Words(English or British) = Uppercase Words + Lowercase Words + Title Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hired-correlation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Word_count():\n",
    "    \"\"\"Getting the count of British and American words using the list above\"\"\"\n",
    "    US_UK,x,y,start_time = Initial()\n",
    "    Title_word_US = list(map(str.title,y))\n",
    "    Upper_word_US = list(map(str.upper,y))\n",
    "    Lower_word_US = list(map(str.lower,y))\n",
    "\n",
    "    Title_word_UK = list(map(str.title,x))\n",
    "    Upper_word_UK = list(map(str.upper,x))\n",
    "    Lower_word_UK = list(map(str.lower,x))\n",
    "\n",
    "    Us_words = [Title_word_US,Upper_word_US,Lower_word_US]\n",
    "    Uk_words = [Title_word_UK,Upper_word_UK,Lower_word_UK]\n",
    "\n",
    "\n",
    "    Words_count_US = []\n",
    "    for i in Us_words:\n",
    "        vocab = i\n",
    "        r = re.compile(\"|\".join(r'\\b%s?\\b' % w for w in vocab))\n",
    "        wordcount_us = Counter(re.findall(r, my_text))\n",
    "\n",
    "        \"\"\" Deleting Words that are redundant \"\"\"\n",
    "        \n",
    "        if '/' or '' or 'to' or 'Dis' or 'To'or 'dis'in wordcount_us:\n",
    "            del wordcount_us['/'],wordcount_us[''],wordcount_us['To'],wordcount_us['to'],wordcount_us['Dis'],wordcount_us['dis']\n",
    "#         print(wordcount_us)\n",
    "            Words_count_US.append(wordcount_us)\n",
    "\n",
    "\n",
    "    Words_count_UK = []\n",
    "    for i in Uk_words:\n",
    "        vocab = i\n",
    "        r = re.compile(\"|\".join(r'\\b%s?\\b' % w for w in vocab))\n",
    "        wordcount_uk = Counter(re.findall(r, my_text))\n",
    "# print(wordcount_uk)\n",
    "#     for k,v in (dict(wordcount_uk)).items:\n",
    "#         print(k)\n",
    "        if '/' or '' or 'to' or 'Dis' or 'To'or 'dis'in wordcount_uk:\n",
    "            del wordcount_uk['/'],wordcount_uk[''],wordcount_uk['To'],wordcount_uk['to'],wordcount_uk['Dis'],wordcount_uk['dis']\n",
    "            Words_count_UK.append(wordcount_uk)\n",
    " \n",
    "    \"\"\"Count of US and UK words are then appended\"\"\"\n",
    "    \n",
    "    count_us = []\n",
    "    for i in Words_count_US:\n",
    "#     for y in i.values:\n",
    "        count_us.append(sum(i.values()))\n",
    "\n",
    "    count_uk = []\n",
    "    for i in Words_count_UK:\n",
    "#     for y in i.values:\n",
    "        count_uk.append(sum(i.values()))\n",
    "    \n",
    "\n",
    "    return US_UK , count_us ,count_uk,Words_count_US,Words_count_UK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instructional-science",
   "metadata": {},
   "source": [
    "Converting the mapped words that are present in the documents into dict value, As there is a posibility that a word can be either Small or Capital and even Title, So each of the presence are mapped to a counter and then to the existing dict \n",
    "\n",
    "After getting the count of both US and UK. Maximum value is then projected for the next process i.e., Transforming the minimum count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "better-arrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dict_words():\n",
    "    US_UK , count_us ,count_uk,Words_count_US,Words_count_UK = Word_count()\n",
    "    dict_uk = {}\n",
    "    dict_us = {}\n",
    "\n",
    "    dict_lower = dict((k.lower(), v.lower()) for k,v in US_UK.items())\n",
    "    dict_upper = dict((k.upper(), v.upper()) for k,v in US_UK.items())\n",
    "    dict_title = dict((k.title(), v.title()) for k,v in US_UK.items())\n",
    "\n",
    "#Inverting Dict from US, UK as Key and Value\n",
    "\n",
    "    inv_dict_lower = {v: k for k, v in dict_lower.items()}\n",
    "    inv_dict_upper = {v: k for k, v in dict_upper.items()}\n",
    "    inv_dict_title = {v: k for k, v in dict_title.items()}\n",
    "\n",
    "\n",
    "\n",
    "    if count_us < count_uk:\n",
    "        for i in Words_count_UK:\n",
    "#     print(len(dict(i).values()))\n",
    "            if len(dict(i).values()) > 0:\n",
    "                for i in dict(i):\n",
    "                    if i.istitle():\n",
    "#                     print(str(i)+ ' : '+ str(dict_title.get(i)))\n",
    "                        dict_us[i] = dict_title.get(i)\n",
    "#                 print(dict_title.get(i))\n",
    "                    if i.islower():\n",
    "#                 print(str(i)+ ' : '+ str(dict_lower.get(i)))\n",
    "                        dict_us[i] = dict_lower.get(i)\n",
    "                    if i.isupper():\n",
    "#                 print(str(i)+ ' : '+ str(dict_upper.get(i)))\n",
    "                        dict_us[i] = dict_lower.get(i)\n",
    " \n",
    "# print(\"----------------------------------------\")\n",
    "    if count_us > count_uk:\n",
    "        for i in Words_count_US:\n",
    "#     print(len(dict(i).values()))\n",
    "            if len(dict(i).values()) > 0:\n",
    "                for i in dict(i):\n",
    "                    if i.istitle():\n",
    "#                 print(str(i)+ ' : '+ str(inv_dict_title.get(i)))\n",
    "                        dict_uk[i] = inv_dict_title.get(i)\n",
    "#                 print(dict_title.get(i))\n",
    "                    if i.islower():\n",
    "#                 print(str(i)+ ' : '+ str(inv_dict_lower.get(i)))\n",
    "                        dict_uk[i] = inv_dict_lower.get(i)\n",
    "                    if i.isupper():\n",
    "#                 print(str(i)+ ' : '+ str(inv_dict_upper.get(i)))\n",
    "                        dict_uk[i] = inv_dict_upper.get(i)\n",
    "    \n",
    "    output = [dict_uk,dict_us]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "married-acrylic",
   "metadata": {},
   "source": [
    "Below value gives us the dict value in terms of keys and values that can be used to transform these words in the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "departmental-blues",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Pulverized': 'Pulverised',\n",
       "  'Utilization': 'Utilisation',\n",
       "  'Aluminum': 'Aluminium',\n",
       "  'Organization': 'Organisation',\n",
       "  'Center': 'Centre',\n",
       "  'Utilizing': 'Utilising',\n",
       "  'Behavioral': 'Behavioural',\n",
       "  'Pediatrics': 'Paediatrics',\n",
       "  'Aging': 'Ageing',\n",
       "  'Harbor': 'Harbour',\n",
       "  'Pediatric': 'Paediatric',\n",
       "  'Modeling': 'Modelling',\n",
       "  'desulfurization': 'desulphurization',\n",
       "  'aluminum': 'aluminium',\n",
       "  'tons': 'tonnes',\n",
       "  'ton': 'tonne',\n",
       "  'utilization': 'utilisation',\n",
       "  'behavior': 'behaviour',\n",
       "  'utilized': 'utilised',\n",
       "  'utilize': 'utilise',\n",
       "  'pulverized': 'pulverised',\n",
       "  'color': 'colour',\n",
       "  'utilizes': 'utilises',\n",
       "  'oxidized': 'oxidised',\n",
       "  'behavioral': 'behavioural',\n",
       "  'sulfur': 'sulphur',\n",
       "  'meters': 'metres',\n",
       "  'practices': 'practises',\n",
       "  'reutilization': 'reutilisation',\n",
       "  'kilometers': 'kilometres',\n",
       "  'programs': 'programmes',\n",
       "  'kilometer': 'kilometre',\n",
       "  'hypothesize': 'hypothesise',\n",
       "  'utilizing': 'utilising',\n",
       "  'neighboring': 'neighbouring',\n",
       "  'neighborhoods': 'neighbourhoods',\n",
       "  'behaviors': 'behaviours',\n",
       "  'pediatric': 'paediatric',\n",
       "  'ionization': 'ionisation',\n",
       "  'tumor': 'tumour',\n",
       "  'defense': 'defence',\n",
       "  'fetal': 'foetal'},\n",
       " {}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dict_words()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genetic-explorer",
   "metadata": {},
   "source": [
    "This function below changes any word without changing the style of the file. This also transforms words that are inside table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "authentic-anime",
   "metadata": {},
   "outputs": [],
   "source": [
    "def docx_replace_regex(doc_obj, regex , replace):\n",
    "\n",
    "    for p in doc_obj.paragraphs:\n",
    "        if regex.search(p.text):\n",
    "            inline = p.runs\n",
    "            # Loop added to work with runs (strings with same style)\n",
    "            for i in range(len(inline)):\n",
    "                if regex.search(inline[i].text):\n",
    "                    text = regex.sub(replace, inline[i].text)\n",
    "                    inline[i].text = text\n",
    "\n",
    "    for table in doc_obj.tables:\n",
    "        for row in table.rows:\n",
    "            for cell in row.cells:\n",
    "                docx_replace_regex(cell, regex , replace)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simplified-sample",
   "metadata": {},
   "source": [
    "Replacement of the words with respect to the maximum count is done using the below code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acute-present",
   "metadata": {},
   "outputs": [],
   "source": [
    "def converter():\n",
    "    coute = []\n",
    "    output = Dict_words()\n",
    "    for i in output:\n",
    "        l = len(i)\n",
    "        coute.append(l)\n",
    "\n",
    "    if coute[0] > coute[1]:\n",
    "        print(\"US is dominating by %s \" % str(round(sum(count_us)/(sum(count_us)+sum(count_uk)),2)*100))\n",
    "    if coute[0] < coute[1]:\n",
    "        print(\"UK is dominating by %s\" % str(round(sum(count_uk)/(sum(count_us)+sum(count_uk)),2)*100))\n",
    "\n",
    "    for i in output:\n",
    "        if len(i) > 0:\n",
    "#         print(range(i))\n",
    "#      for i in tqdm(i, len(i)):\n",
    "#         print(i)\n",
    "            for word, replacement in tqdm(i.items()):\n",
    "                word_re=re.compile(r'\\b%s\\b' %word)\n",
    "                docx_replace_regex(doc, word_re , replacement)\n",
    "            print(\"Done with Replacement\")\n",
    "            doc.save(output_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "mediterranean-reserve",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization has begun...\n",
      "---------------------------\n",
      "US Word count: 96\n",
      "UK Word count: 20\n",
      "---------------------------\n",
      "US is dominating by 83.0 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9234cc77d0c416ab1426d358748c1b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with Replacement\n",
      "Overall code Execution time : 15.47\n",
      "Coverter code Execution time : 7.69\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    start_time = timeit.default_timer()\n",
    "    print(\"Initialization has begun...\")\n",
    "    Initial()\n",
    "    print(\"---------------------------\")\n",
    "    US_UK , count_us ,count_uk,Words_count_US,Words_count_UK = Word_count()\n",
    "    print(\"US Word count: \" + str(sum(count_us)))\n",
    "    print(\"UK Word count: \" + str(sum(count_uk)))\n",
    "    print(\"---------------------------\")\n",
    "    Dict_words()\n",
    "    start_time_ = timeit.default_timer()\n",
    "    converter()\n",
    "    print(\"Overall code Execution time : {0:.2f}\".format(timeit.default_timer() - start_time))\n",
    "    print(\"Coverter code Execution time : {0:.2f}\".format(timeit.default_timer() - start_time_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
